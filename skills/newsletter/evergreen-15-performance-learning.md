---
name: newsletter-performance-learning
description: Analyzes completed newsletter performance to identify patterns and refine future content strategies. Use after each newsletter publish to capture learnings, track what works, and adjust future execution. Feeds continuous improvement loop.
---

# Newsletter Performance Learning

Analyze completed newsletter performance against success metrics. Identify patterns in high and low performers. Surface actionable insights to refine future newsletter decisions. Build institutional knowledge over time.

## Input Requirements
- Newsletter ID (relation â†’ Editorial Outputs in Notion)
- Newsletter metadata (topic, subject line used, word count, structure, etc.)
- Performance data:
  - Open rate (percentage)
  - Click rate (percentage)
  - Reply volume (count)
  - Unsubscribe rate (percentage)
  - Time to open (hours after send)

## Performance Tiers

### High Performer
- Open rate: >35%
- Click rate: >5%
- Reply volume: >10 replies
- Unsubscribe rate: <0.5%

### Average Performer
- Open rate: 25-35%
- Click rate: 2-5%
- Reply volume: 3-10 replies
- Unsubscribe rate: 0.5-1%

### Low Performer
- Open rate: <25%
- Click rate: <2%
- Reply volume: <3 replies
- Unsubscribe rate: >1%

## Analysis Framework

### What to Analyze

#### Subject Line Performance
**Track:**
- Which formula performed best? (personal discovery, practical, opinion, question, etc.)
- Character count correlation with opens
- Curiosity vs. clarity balance
- Seasonal/timely hooks vs. evergreen

#### Content Topic Performance
**Track:**
- Topic type (technique, recipe, ingredient spotlight, cultural story)
- Seasonal alignment (did timing matter?)
- Complexity level (beginner vs. intermediate)
- Cultural depth (surface vs. deep cultural context)

#### Opening Hook Performance
**Track:**
- Hook type (personal story, sensory moment, question, surprising fact)
- Length of opening (100-150 words optimal?)
- Time to main topic (immediate vs. gradual)

#### CTA Performance
**Track:**
- CTA type (action, reflection, connection)
- Placement (middle vs. end only)
- Specificity (vague "let me know" vs. specific "tell me your curry leaf situation")

## Always Do
- Analyze every newsletter post-publish (no exceptions)
- Compare performance to historical average
- Identify specific elements that drove success or failure
- Log findings to Historical Files immediately (while fresh)
- Generate specific, actionable recommendations for next newsletter
- Track patterns across multiple newsletters (not just one-offs)
- Celebrate what worked (document successes for replication)
- Learn from failures without defensiveness (honest assessment)

## Never Do
- Skip performance analysis (even for "average" newsletters)
- Make vague assessments ("It did okay") without specifics
- Change too many variables at once (can't identify what worked)
- Ignore patterns because they contradict assumptions
- Fail to log learnings (institutional knowledge is lost)
- Blame external factors without analyzing controllable elements
- Assume correlation = causation without testing (validate patterns)

## Cross-Skill Dependencies
- **Receives from:** Published newsletter + ESP performance data
- **Feeds into:** All future newsletter skills (informs strategy)
- **Updates:** Historical Files (builds institutional knowledge)
- **Informs:** `newsletter-orchestration-jam-lab` (strategic adjustments over time)
